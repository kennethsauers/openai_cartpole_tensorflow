{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import model\n",
    "import random\n",
    "goal_steps = 500\n",
    "initial_games = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class agents():\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(\"CartPole-v0\")\n",
    "        self.model = model.neural_network_model(4)\n",
    "        self.model.load('model_save/test')\n",
    "    def play(self, render = False, num = 100):\n",
    "        scores = []\n",
    "        choices = []\n",
    "        for each_game in range(num):\n",
    "            score = 0\n",
    "            game_memory = []\n",
    "            prev_obs = []\n",
    "            self.env.reset()\n",
    "            for _ in range(goal_steps):\n",
    "                if render:\n",
    "                    self.env.render()\n",
    "\n",
    "                if len(prev_obs)==0:\n",
    "                    action = random.randrange(0,2)\n",
    "                else:\n",
    "                    action = np.argmax(self.model.predict(prev_obs.reshape(-1,len(prev_obs),1))[0])\n",
    "\n",
    "                choices.append(action)\n",
    "\n",
    "                new_observation, reward, done, info = self.env.step(action)\n",
    "                prev_obs = new_observation\n",
    "                game_memory.append([new_observation, action])\n",
    "                score+=reward\n",
    "                if done: break\n",
    "\n",
    "            scores.append(score)\n",
    "\n",
    "        print('Average Score:',sum(scores)/len(scores))\n",
    "        print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-28 15:51:45,536] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/hedonist/Documents/openai_cartpole_tensorflow/model_save/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-28 15:51:46,355] Restoring parameters from /home/hedonist/Documents/openai_cartpole_tensorflow/model_save/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 10.52\n",
      "choice 1:0.05038022813688213  choice 0:0.9496197718631179\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    n = agents()\n",
    "    n.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
