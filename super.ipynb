{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from statistics import median, mean\n",
    "from collections import Counter\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class agent():\n",
    "    def __init__(self):\n",
    "        self.LR = 1e-3\n",
    "        self.env = gym.make(\"CartPole-v0\")\n",
    "        self.model = self.neural_network_model()\n",
    "        self.env.reset()\n",
    "        self.goal_steps = 500\n",
    "        self.score_requirement = 55\n",
    "        self.initial_games = 100000\n",
    "        \n",
    "        self.np_save_path = 'data_save'\n",
    "        self.np_file = self.np_save_path + '/data.npy'\n",
    "        if not os.path.exists(self.np_save_path):\n",
    "            os.makedirs(self.np_save_path)\n",
    "            \n",
    "        self.model_save_path = 'model_save'\n",
    "        self.model_name = self.model_save_path +'/save'\n",
    "        if not os.path.exists(self.model_save_path):\n",
    "            os.makedirs(self.model_save_path)\n",
    "        \n",
    "    def neural_network_model(self):\n",
    "        keep = 0.8\n",
    "        input_size = 4\n",
    "        LR = 1e-3\n",
    "        network = input_data(shape=[None, input_size, 1], name='input')\n",
    "        network = fully_connected(network, 128, activation='relu', name = 'hidden_1')\n",
    "        network = dropout(network,keep)\n",
    "        network = fully_connected(network, 256, activation='relu', name = 'hidden_2')\n",
    "        network = dropout(network,keep)\n",
    "        network = fully_connected(network, 512, activation='relu', name = 'hidden_3')\n",
    "        network = dropout(network,keep)\n",
    "        network = fully_connected(network, 256, activation='relu', name = 'hidden_4')\n",
    "        network = dropout(network,keep)\n",
    "        network = fully_connected(network, 128, activation='relu', name = 'hidden_5')\n",
    "        network = dropout(network,keep)\n",
    "        network = fully_connected(network, 2, activation='softmax', name = 'softmax')\n",
    "        network = regression(network, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "        model = tflearn.DNN(network, tensorboard_verbose=3)\n",
    "        return model\n",
    "        \n",
    "    def generate_data(self):\n",
    "        training_data = []\n",
    "        scores = []\n",
    "        accepted_scores = []\n",
    "        for _ in range(self.initial_games):\n",
    "            score = 0\n",
    "            game_memory = []\n",
    "            prev_observation = []\n",
    "            for _ in range(self.goal_steps):\n",
    "                action = random.randrange(0,2)\n",
    "                observation, reward, done, info = self.env.step(action)\n",
    "\n",
    "                if len(prev_observation) > 0 :\n",
    "                    game_memory.append([prev_observation, action])\n",
    "                prev_observation = observation\n",
    "                score+=reward\n",
    "                if done: break\n",
    "\n",
    "            if score >= self.score_requirement:\n",
    "                accepted_scores.append(score)\n",
    "                for data in game_memory:\n",
    "                    if data[1] == 1:\n",
    "                        output = [0,1]\n",
    "                    elif data[1] == 0:\n",
    "                        output = [1,0]\n",
    "\n",
    "                    training_data.append([data[0], output])\n",
    "\n",
    "            self.env.reset()\n",
    "            scores.append(score)\n",
    "\n",
    "        training_data_save = np.array(training_data)\n",
    "        np.save(self.np_file ,training_data_save)\n",
    "        print('Average accepted score:',mean(accepted_scores))\n",
    "        print('Median score for accepted scores:',median(accepted_scores))\n",
    "        print(Counter(accepted_scores))\n",
    "\n",
    "        return training_data\n",
    "    \n",
    "    def train_model(self, model=False):\n",
    "        training_data = np.load(self.np_file)\n",
    "        X = np.array([i[0] for i in training_data]).reshape(-1,len(training_data[0][0]),1)\n",
    "        y = [i[1] for i in training_data]\n",
    "        keep = 0.8\n",
    "        self.model.fit({'input': X}, {'targets': y}, n_epoch=1, snapshot_step=500, show_metric=True, run_id='openai_learning')\n",
    "        self.model.save(self.model_name)\n",
    "        return model\n",
    "    \n",
    "    def play(self, render = False, num = 100, load = False):\n",
    "        scores = []\n",
    "        choices = []\n",
    "        if load:\n",
    "            self.model.load(self.model_name)\n",
    "        for each_game in range(num):\n",
    "            score = 0\n",
    "            game_memory = []\n",
    "            prev_obs = []\n",
    "            self.env.reset()\n",
    "            for _ in range(self.goal_steps):\n",
    "                if render:\n",
    "                    self.env.render()\n",
    "\n",
    "                if len(prev_obs)==0:\n",
    "                    action = random.randrange(0,2)\n",
    "                else:\n",
    "                    action = np.argmax(self.model.predict(prev_obs.reshape(-1,len(prev_obs),1))[0])\n",
    "\n",
    "                choices.append(action)\n",
    "\n",
    "                new_observation, reward, done, info = self.env.step(action)\n",
    "                prev_obs = new_observation\n",
    "                game_memory.append([new_observation, action])\n",
    "                score+=reward\n",
    "                if done: break\n",
    "            scores.append(score)\n",
    "\n",
    "        print('Average Score:',sum(scores)/len(scores))\n",
    "        print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "    \n",
    "    def run(self):\n",
    "        self.generate_data()\n",
    "        self.train_model()\n",
    "        self.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2510  | total loss: \u001b[1m\u001b[32m0.66455\u001b[0m\u001b[0m | time: 77.032s\n",
      "| Adam | epoch: 001 | loss: 0.66455 - acc: 0.5900 -- iter: 160640/160689\n",
      "Training Step: 2511  | total loss: \u001b[1m\u001b[32m0.66324\u001b[0m\u001b[0m | time: 77.063s\n",
      "| Adam | epoch: 001 | loss: 0.66324 - acc: 0.5888 -- iter: 160689/160689\n",
      "--\n",
      "INFO:tensorflow:/home/hedonist/Documents/openai_cartpole_tensorflow/openai_cartpole_tensorflow-c42f2a06aac81efa295bf1f7537b6423ac768f52/model_save/save is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-30 16:04:28,202] /home/hedonist/Documents/openai_cartpole_tensorflow/openai_cartpole_tensorflow-c42f2a06aac81efa295bf1f7537b6423ac768f52/model_save/save is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 134.46\n",
      "choice 1:0.5105607615647776  choice 0:0.48943923843522236\n"
     ]
    }
   ],
   "source": [
    "more = agent()\n",
    "more.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/hedonist/Documents/openai_cartpole_tensorflow/openai_cartpole_tensorflow-c42f2a06aac81efa295bf1f7537b6423ac768f52/model_save/save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-30 16:04:36,433] Restoring parameters from /home/hedonist/Documents/openai_cartpole_tensorflow/openai_cartpole_tensorflow-c42f2a06aac81efa295bf1f7537b6423ac768f52/model_save/save\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 126.23\n",
      "choice 1:0.5110512556444585  choice 0:0.4889487443555415\n"
     ]
    }
   ],
   "source": [
    "more.play(load = True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
